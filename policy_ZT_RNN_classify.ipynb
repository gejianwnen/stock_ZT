{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tushare as ts\n",
    "ts.set_token('29eaf3bcac23df4c6d025de157ab2d53beead3391fbe6e83b4ebcb6c')\n",
    "pro = ts.pro_api()\n",
    "\n",
    "import mpl_finance as mpf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "from matplotlib.pylab import date2num\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "mpl.rcParams['font.family'] = 'sans-serif'\n",
    "mpl.rcParams['font.sans-serif'] = 'SimHei'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyDatasetZT(Dataset):\n",
    "    def __init__(self, df, transform=None, target_transform=None):\n",
    "        self.info_df = df\n",
    "        self.imgs = df[\"file_name\"].values\n",
    "        self.labels = df[\"label\"].values\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filename = self.imgs[index]\n",
    "        label = self.labels[index]\n",
    "        img = pd.read_csv(filename)\n",
    "        img = img.fillna(0)\n",
    "        img = img.values[:,:11]   # 行，列\n",
    "        img[-1,2:10] = 0\n",
    "#         img[-1,11:] = 0\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img,label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "# Hyper Parameters\n",
    "EPOCH = 1               # train the training data n times, to save time, we just train 1 epoch\n",
    "BATCH_SIZE = 256\n",
    "TIME_STEP = 64          # rnn time step / image height\n",
    "INPUT_SIZE = 11         # rnn input size / image width\n",
    "LR = 1e-5             # learning rate\n",
    "LOAD_MODEL = not True\n",
    "\n",
    "# test created dataset\n",
    "info_df = pd.read_csv(\"./data/deeplearning_data/train_data/\"+\"info.csv\")\n",
    "dataset_ZT = MyDatasetZT(info_df )\n",
    "train_loader = DataLoader(dataset_ZT, batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([256, 64, 11]) torch.Size([256])\n",
      "1 torch.Size([256, 64, 11]) torch.Size([256])\n",
      "2 torch.Size([256, 64, 11]) torch.Size([256])\n",
      "3 torch.Size([256, 64, 11]) torch.Size([256])\n",
      "4 torch.Size([256, 64, 11]) torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "for i, (batch_x, batch_y) in enumerate(train_loader):\n",
    "    if(i>4):\n",
    "        break\n",
    "    print(i, batch_x.size(),batch_y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,num_layers):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.rnn = nn.LSTM(         # if use nn.RNN(), it hardly learns\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,         # rnn hidden unit\n",
    "            num_layers=num_layers,           # number of rnn layer\n",
    "            batch_first=True,       # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)\n",
    "            bidirectional = not True\n",
    "        )\n",
    "        self.out = nn.Linear(hidden_size, 2)  # if bidirection the input size should plus 2\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape (batch, time_step, input_size)\n",
    "        # r_out shape (batch, time_step, output_size)\n",
    "        # h_n shape (n_layers, batch, hidden_size)\n",
    "        # h_c shape (n_layers, batch, hidden_size)\n",
    "        r_out, (h_n, h_c) = self.rnn(x, None)   # None represents zero initial hidden state\n",
    "        # choose r_out at the last time step\n",
    "        out = self.out(r_out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): LSTM(11, 32, batch_first=True)\n",
      "  (out): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n",
      "step:  1 | train loss: 0.6943 | train accuracy: 0.48\n",
      "step:  3 | train loss: 0.6963 | train accuracy: 0.48\n",
      "step:  5 | train loss: 0.6902 | train accuracy: 0.54\n",
      "step:  7 | train loss: 0.6927 | train accuracy: 0.52\n",
      "step:  9 | train loss: 0.6922 | train accuracy: 0.51\n",
      "step:  11 | train loss: 0.6921 | train accuracy: 0.51\n",
      "step:  13 | train loss: 0.6906 | train accuracy: 0.55\n",
      "step:  15 | train loss: 0.6900 | train accuracy: 0.54\n",
      "step:  17 | train loss: 0.6923 | train accuracy: 0.49\n",
      "step:  19 | train loss: 0.6931 | train accuracy: 0.49\n",
      "step:  21 | train loss: 0.6904 | train accuracy: 0.55\n",
      "step:  23 | train loss: 0.6929 | train accuracy: 0.53\n",
      "step:  25 | train loss: 0.6914 | train accuracy: 0.54\n",
      "step:  27 | train loss: 0.6947 | train accuracy: 0.46\n",
      "step:  29 | train loss: 0.6907 | train accuracy: 0.55\n",
      "step:  31 | train loss: 0.6931 | train accuracy: 0.48\n",
      "step:  33 | train loss: 0.6910 | train accuracy: 0.52\n",
      "step:  35 | train loss: 0.6941 | train accuracy: 0.48\n",
      "step:  37 | train loss: 0.6910 | train accuracy: 0.53\n",
      "step:  39 | train loss: 0.6916 | train accuracy: 0.54\n",
      "step:  41 | train loss: 0.6912 | train accuracy: 0.51\n",
      "step:  43 | train loss: 0.6943 | train accuracy: 0.50\n",
      "step:  45 | train loss: 0.6938 | train accuracy: 0.48\n",
      "step:  47 | train loss: 0.6969 | train accuracy: 0.44\n",
      "step:  49 | train loss: 0.6910 | train accuracy: 0.52\n",
      "step:  51 | train loss: 0.6930 | train accuracy: 0.49\n",
      "step:  53 | train loss: 0.6899 | train accuracy: 0.54\n",
      "step:  55 | train loss: 0.6962 | train accuracy: 0.46\n",
      "step:  57 | train loss: 0.6923 | train accuracy: 0.53\n",
      "step:  59 | train loss: 0.6947 | train accuracy: 0.50\n",
      "step:  61 | train loss: 0.6931 | train accuracy: 0.49\n",
      "step:  63 | train loss: 0.6919 | train accuracy: 0.50\n",
      "step:  65 | train loss: 0.6901 | train accuracy: 0.56\n",
      "step:  67 | train loss: 0.6897 | train accuracy: 0.53\n",
      "step:  69 | train loss: 0.6958 | train accuracy: 0.46\n",
      "step:  71 | train loss: 0.6937 | train accuracy: 0.49\n",
      "step:  73 | train loss: 0.6875 | train accuracy: 0.57\n",
      "step:  75 | train loss: 0.6921 | train accuracy: 0.51\n",
      "step:  77 | train loss: 0.6899 | train accuracy: 0.56\n",
      "step:  79 | train loss: 0.6898 | train accuracy: 0.54\n",
      "step:  81 | train loss: 0.6895 | train accuracy: 0.56\n",
      "step:  83 | train loss: 0.6895 | train accuracy: 0.51\n",
      "step:  85 | train loss: 0.6915 | train accuracy: 0.54\n",
      "step:  87 | train loss: 0.6900 | train accuracy: 0.54\n",
      "step:  89 | train loss: 0.6905 | train accuracy: 0.53\n",
      "step:  91 | train loss: 0.6928 | train accuracy: 0.49\n",
      "step:  93 | train loss: 0.6897 | train accuracy: 0.52\n",
      "step:  95 | train loss: 0.6892 | train accuracy: 0.56\n",
      "step:  97 | train loss: 0.6922 | train accuracy: 0.50\n",
      "step:  99 | train loss: 0.6955 | train accuracy: 0.47\n",
      "step:  101 | train loss: 0.6921 | train accuracy: 0.50\n",
      "step:  103 | train loss: 0.6916 | train accuracy: 0.53\n",
      "step:  105 | train loss: 0.6919 | train accuracy: 0.52\n",
      "step:  107 | train loss: 0.6935 | train accuracy: 0.51\n",
      "step:  109 | train loss: 0.6908 | train accuracy: 0.55\n",
      "step:  111 | train loss: 0.6892 | train accuracy: 0.53\n",
      "step:  113 | train loss: 0.6863 | train accuracy: 0.60\n",
      "step:  115 | train loss: 0.6904 | train accuracy: 0.50\n",
      "step:  117 | train loss: 0.6907 | train accuracy: 0.56\n",
      "step:  119 | train loss: 0.6932 | train accuracy: 0.48\n",
      "step:  121 | train loss: 0.6913 | train accuracy: 0.52\n",
      "step:  123 | train loss: 0.6911 | train accuracy: 0.52\n",
      "step:  125 | train loss: 0.6895 | train accuracy: 0.54\n",
      "step:  127 | train loss: 0.6907 | train accuracy: 0.55\n",
      "step:  129 | train loss: 0.6892 | train accuracy: 0.53\n",
      "step:  131 | train loss: 0.6893 | train accuracy: 0.57\n",
      "step:  133 | train loss: 0.6906 | train accuracy: 0.54\n",
      "step:  135 | train loss: 0.6875 | train accuracy: 0.57\n",
      "step:  137 | train loss: 0.6922 | train accuracy: 0.52\n",
      "step:  139 | train loss: 0.6894 | train accuracy: 0.54\n",
      "step:  141 | train loss: 0.6903 | train accuracy: 0.54\n",
      "step:  143 | train loss: 0.6914 | train accuracy: 0.50\n",
      "step:  145 | train loss: 0.6941 | train accuracy: 0.47\n",
      "step:  147 | train loss: 0.6880 | train accuracy: 0.55\n",
      "step:  149 | train loss: 0.6923 | train accuracy: 0.49\n",
      "step:  151 | train loss: 0.6894 | train accuracy: 0.55\n",
      "step:  153 | train loss: 0.6911 | train accuracy: 0.52\n",
      "step:  155 | train loss: 0.6876 | train accuracy: 0.59\n",
      "step:  157 | train loss: 0.6899 | train accuracy: 0.57\n",
      "step:  159 | train loss: 0.6894 | train accuracy: 0.52\n",
      "step:  161 | train loss: 0.6927 | train accuracy: 0.52\n",
      "step:  163 | train loss: 0.6932 | train accuracy: 0.46\n",
      "step:  165 | train loss: 0.6915 | train accuracy: 0.53\n",
      "step:  167 | train loss: 0.6922 | train accuracy: 0.52\n",
      "step:  169 | train loss: 0.6873 | train accuracy: 0.56\n",
      "step:  171 | train loss: 0.6909 | train accuracy: 0.51\n",
      "step:  173 | train loss: 0.6912 | train accuracy: 0.52\n",
      "step:  175 | train loss: 0.6896 | train accuracy: 0.51\n",
      "step:  177 | train loss: 0.6889 | train accuracy: 0.56\n",
      "step:  179 | train loss: 0.6943 | train accuracy: 0.48\n",
      "step:  181 | train loss: 0.6926 | train accuracy: 0.50\n",
      "step:  183 | train loss: 0.6873 | train accuracy: 0.57\n",
      "step:  185 | train loss: 0.6902 | train accuracy: 0.50\n",
      "step:  187 | train loss: 0.6948 | train accuracy: 0.48\n",
      "step:  189 | train loss: 0.6918 | train accuracy: 0.51\n",
      "step:  191 | train loss: 0.6882 | train accuracy: 0.58\n",
      "step:  193 | train loss: 0.6884 | train accuracy: 0.56\n",
      "step:  195 | train loss: 0.6920 | train accuracy: 0.53\n",
      "step:  197 | train loss: 0.6898 | train accuracy: 0.53\n",
      "step:  199 | train loss: 0.6880 | train accuracy: 0.55\n",
      "step:  201 | train loss: 0.6922 | train accuracy: 0.51\n",
      "step:  203 | train loss: 0.6940 | train accuracy: 0.46\n",
      "step:  205 | train loss: 0.6893 | train accuracy: 0.56\n",
      "step:  207 | train loss: 0.6929 | train accuracy: 0.49\n",
      "step:  209 | train loss: 0.6919 | train accuracy: 0.50\n",
      "step:  211 | train loss: 0.6926 | train accuracy: 0.50\n",
      "step:  213 | train loss: 0.6848 | train accuracy: 0.62\n",
      "step:  215 | train loss: 0.6900 | train accuracy: 0.53\n",
      "step:  217 | train loss: 0.6878 | train accuracy: 0.56\n",
      "step:  219 | train loss: 0.6886 | train accuracy: 0.56\n",
      "step:  221 | train loss: 0.6923 | train accuracy: 0.50\n",
      "step:  223 | train loss: 0.6931 | train accuracy: 0.48\n",
      "step:  225 | train loss: 0.6946 | train accuracy: 0.48\n",
      "step:  227 | train loss: 0.6921 | train accuracy: 0.52\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "rnn = RNN(input_size = 11, hidden_size = 32, num_layers = 1)\n",
    "try:\n",
    "    if LOAD_MODEL:\n",
    "        print(\"load model\")\n",
    "        rnn.load_state_dict(torch.load(\"./rnn.pth\"))\n",
    "except:\n",
    "    print(\"no previous cache\")\n",
    "print(rnn)\n",
    "LR = 1e-5\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR )   # optimize all cnn parameters\n",
    "loss_func = nn.CrossEntropyLoss() \n",
    "# loss_func = nn.BCEWithLogitsLoss()                       # the target label is not one-hotted\n",
    "# loss_func = nn.BCELoss() \n",
    "\n",
    "# training and testing\n",
    "for epoch in range(EPOCH):\n",
    "    rnn.train()\n",
    "    train_acc = 0.0\n",
    "    train_loss = 0.0\n",
    "    for step, (b_x, b_y) in enumerate(train_loader):        # gives batch data\n",
    "#        print(b_x.size())\n",
    "#         b_x = b_x.view(-1, 28, 28)              # reshape x to (batch, time_step, input_size)\n",
    "#        print(b_x.size())\n",
    "        b_x = torch.tensor(b_x, dtype=torch.float32)\n",
    "        output = rnn(b_x)                               # rnn output\n",
    "#         b_y_onehot = torch.nn.functional.one_hot(b_y, 2) \n",
    "#         b_y_onehot = torch.tensor(b_y_onehot, dtype=torch.float32)\n",
    "        loss = loss_func(output, b_y)                   # cross entropy loss\n",
    "        optimizer.zero_grad()                           # clear gradients for this training step\n",
    "        loss.backward()                                 # backpropagation, compute gradients\n",
    "        optimizer.step()                                # apply gradients\n",
    "        _, pred_y = torch.max(output, 1)\n",
    "        \n",
    "        train_loss += loss*BATCH_SIZE\n",
    "        train_acc += (pred_y == b_y).float().sum()\n",
    "            \n",
    "        if step % 2 == 0:\n",
    "            accuracy = (pred_y == b_y).float().mean()\n",
    "            print('step: ', step+1, '| train loss: %.4f' % loss.data, '| train accuracy: %.2f' % accuracy)\n",
    "    print(f'Train loss: {train_loss/len(train_data): .6f} train acc: {train_acc/len(train_data):.4f}')\n",
    "        \n",
    "torch.save(rnn.state_dict(),\"./rnn.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "'''\n",
    "    rnn.eval()\n",
    "    test_loss = 0.0\n",
    "    test_acc = 0.0\n",
    "    for i, (b_x, b_y) in enumerate(test_loader):\n",
    "        b_x = b_x.view(-1, 28, 28)              # reshape x to (batch, time_step, input_size)\n",
    "#        assert c == 1, 'channel must be 1'\n",
    "#        img = img.squeeze(1)\n",
    "#        print(b_x.size())\n",
    "        if use_gpu:\n",
    "            b_x = b_x.cuda()\n",
    "            b_y = b_y.cuda()\n",
    "        output = rnn(b_x)                               # rnn output\n",
    "        loss = loss_func(output, b_y) \n",
    "        \n",
    "        _, pred_y = torch.max(output, 1)\n",
    "        accuracy = (pred_y == b_y).float().sum()\n",
    "        test_loss += loss*BATCH_SIZE\n",
    "        test_acc += accuracy\n",
    "        \n",
    "    print(f'Test loss: {test_loss/len(test_data): .6f} test acc: {test_acc/len(test_data):.4f}')\n",
    "    print()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37-stock",
   "language": "python",
   "name": "py37-stock"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
