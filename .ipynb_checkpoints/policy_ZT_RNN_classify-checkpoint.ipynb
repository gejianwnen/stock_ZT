{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tushare as ts\n",
    "ts.set_token('29eaf3bcac23df4c6d025de157ab2d53beead3391fbe6e83b4ebcb6c')\n",
    "pro = ts.pro_api()\n",
    "\n",
    "import mpl_finance as mpf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "from matplotlib.pylab import date2num\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "mpl.rcParams['font.family'] = 'sans-serif'\n",
    "mpl.rcParams['font.sans-serif'] = 'SimHei'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyDatasetZT(Dataset):\n",
    "    def __init__(self, df, transform=None, target_transform=None):\n",
    "        self.info_df = df\n",
    "        self.imgs = df[\"file_name\"].values\n",
    "        self.labels = df[\"label\"].values\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filename = self.imgs[index]\n",
    "        label = self.labels[index]\n",
    "        img = pd.read_csv(filename)\n",
    "        img = img.values\n",
    "        img[-1,2:10] = 0\n",
    "        img[-1,11:] = 0\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img,label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "# Hyper Parameters\n",
    "EPOCH = 1               # train the training data n times, to save time, we just train 1 epoch\n",
    "BATCH_SIZE = 128\n",
    "TIME_STEP = 64          # rnn time step / image height\n",
    "INPUT_SIZE = 18         # rnn input size / image width\n",
    "LR = 1e-5             # learning rate\n",
    "LOAD_MODEL = not True\n",
    "\n",
    "# test created dataset\n",
    "info_df = pd.read_csv(\"./data/deeplearning_data/train_data/\"+\"info.csv\")\n",
    "dataset_ZT = MyDatasetZT(info_df )\n",
    "train_loader = DataLoader(dataset_ZT, batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([128, 64, 18]) torch.Size([128])\n",
      "1 torch.Size([128, 64, 18]) torch.Size([128])\n",
      "2 torch.Size([128, 64, 18]) torch.Size([128])\n",
      "3 torch.Size([128, 64, 18]) torch.Size([128])\n",
      "4 torch.Size([128, 64, 18]) torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "for i, (batch_x, batch_y) in enumerate(train_loader):\n",
    "    if(i>4):\n",
    "        break\n",
    "    print(i, batch_x.size(),batch_y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,num_layers):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.rnn = nn.LSTM(         # if use nn.RNN(), it hardly learns\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,         # rnn hidden unit\n",
    "            num_layers=num_layers,           # number of rnn layer\n",
    "            batch_first=True,       # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)\n",
    "            bidirectional = not True\n",
    "        )\n",
    "        self.out = nn.Linear(hidden_size, 2)  # if bidirection the input size should plus 2\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape (batch, time_step, input_size)\n",
    "        # r_out shape (batch, time_step, output_size)\n",
    "        # h_n shape (n_layers, batch, hidden_size)\n",
    "        # h_c shape (n_layers, batch, hidden_size)\n",
    "        r_out, (h_n, h_c) = self.rnn(x, None)   # None represents zero initial hidden state\n",
    "        # choose r_out at the last time step\n",
    "        out = self.out(r_out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): LSTM(18, 32, num_layers=2, batch_first=True)\n",
      "  (out): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "output with backend CPU and dtype Long doesn't match the desired backend CPU and dtype Float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-03e48476754f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_x\u001b[0m\u001b[1;33m)\u001b[0m                               \u001b[1;31m# rnn output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mb_y_onehot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_y_onehot\u001b[0m\u001b[1;33m)\u001b[0m                   \u001b[1;31m# cross entropy loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m                           \u001b[1;31m# clear gradients for this training step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m                                 \u001b[1;31m# backpropagation, compute gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\admin\\Anaconda3\\envs\\py37-stock\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\admin\\Anaconda3\\envs\\py37-stock\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    615\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 617\u001b[1;33m                                                   reduction=self.reduction)\n\u001b[0m\u001b[0;32m    618\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\admin\\Anaconda3\\envs\\py37-stock\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[1;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[0;32m   2161\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2163\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: output with backend CPU and dtype Long doesn't match the desired backend CPU and dtype Float"
     ]
    }
   ],
   "source": [
    "# train\n",
    "rnn = RNN(input_size = 18, hidden_size = 32, num_layers = 2)\n",
    "try:\n",
    "    if LOAD_MODEL:\n",
    "        rnn.load_state_dict(torch.load(\"./rnn.pth\"))\n",
    "except:\n",
    "    print(\"no previous cache\")\n",
    "print(rnn)\n",
    "    \n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "loss_func = nn.BCEWithLogitsLoss()                       # the target label is not one-hotted\n",
    "# loss_func = nn.BCELoss() \n",
    "\n",
    "# training and testing\n",
    "for epoch in range(EPOCH):\n",
    "    rnn.train()\n",
    "    train_acc = 0.0\n",
    "    train_loss = 0.0\n",
    "    for step, (b_x, b_y) in enumerate(train_loader):        # gives batch data\n",
    "#        print(b_x.size())\n",
    "#         b_x = b_x.view(-1, 28, 28)              # reshape x to (batch, time_step, input_size)\n",
    "#        print(b_x.size())\n",
    "        b_x = torch.tensor(b_x, dtype=torch.float32)\n",
    "        output = rnn(b_x)                               # rnn output\n",
    "        b_y_onehot = torch.nn.functional.one_hot(b_y, 2) \n",
    "        b_y_onehot = torch.tensor(b_y_onehot, dtype=torch.float32)\n",
    "        loss = loss_func(output, b_y_onehot)                   # cross entropy loss\n",
    "        optimizer.zero_grad()                           # clear gradients for this training step\n",
    "        loss.backward()                                 # backpropagation, compute gradients\n",
    "        optimizer.step()                                # apply gradients\n",
    "        _, pred_y = torch.max(output, 1)\n",
    "        \n",
    "        train_loss += loss*BATCH_SIZE\n",
    "        train_acc += (pred_y == b_y).float().sum()\n",
    "            \n",
    "        if step % 100 == 0:\n",
    "            accuracy = (pred_y == b_y).float().mean()\n",
    "            print('Epoch: ', epoch+1, '| train loss: %.4f' % loss.data, '| train accuracy: %.2f' % accuracy)\n",
    "    print(f'Train loss: {train_loss/len(train_data): .6f} train acc: {train_acc/len(train_data):.4f}')\n",
    "        \n",
    "torch.save(rnn.state_dict(),\"./rnn.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "'''\n",
    "    rnn.eval()\n",
    "    test_loss = 0.0\n",
    "    test_acc = 0.0\n",
    "    for i, (b_x, b_y) in enumerate(test_loader):\n",
    "        b_x = b_x.view(-1, 28, 28)              # reshape x to (batch, time_step, input_size)\n",
    "#        assert c == 1, 'channel must be 1'\n",
    "#        img = img.squeeze(1)\n",
    "#        print(b_x.size())\n",
    "        if use_gpu:\n",
    "            b_x = b_x.cuda()\n",
    "            b_y = b_y.cuda()\n",
    "        output = rnn(b_x)                               # rnn output\n",
    "        loss = loss_func(output, b_y) \n",
    "        \n",
    "        _, pred_y = torch.max(output, 1)\n",
    "        accuracy = (pred_y == b_y).float().sum()\n",
    "        test_loss += loss*BATCH_SIZE\n",
    "        test_acc += accuracy\n",
    "        \n",
    "    print(f'Test loss: {test_loss/len(test_data): .6f} test acc: {test_acc/len(test_data):.4f}')\n",
    "    print()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37-stock",
   "language": "python",
   "name": "py37-stock"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
